{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ad8LXysTh9F_"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7kXZuouiHvQ"},"outputs":[],"source":["#Define image size and batch size\n","IMG_SIZE = 224\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"du2DVYCliJDj"},"outputs":[],"source":["#Coding\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8315,"status":"ok","timestamp":1709307229653,"user":{"displayName":"Sahedha","userId":"16315292914001177727"},"user_tz":-330},"id":"cKaM1tvaiQrO","outputId":"8668327a-3edb-4954-c253-13706c534c39"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2408 images belonging to 2 classes.\n"]}],"source":["#Creating training data with above parameters\n","#folder = parameters.flow_from_directory(path,ts,bs,cm,subset)\n","train_generator = train_datagen.flow_from_directory(\n","    r'/content/drive/MyDrive/Brain_Tumor_Detection/Train',\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='training'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1709307233854,"user":{"displayName":"Sahedha","userId":"16315292914001177727"},"user_tz":-330},"id":"jS2G63-wiQb3","outputId":"5910cef4-5507-45b2-d721-907751c7958c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 601 images belonging to 2 classes.\n"]}],"source":["#creating validation data\n","val_generator = train_datagen.flow_from_directory(\n","    r'/content/drive/MyDrive/Brain_Tumor_Detection/Train',\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='validation'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVe627IQiZ40"},"outputs":[],"source":["#Define the model\n","model = keras.Sequential([\n","    layers.Conv2D(32,(3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE,3)),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Conv2D(64,(3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Conv2D(128,(3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Flatten(),\n","    layers.Dense(128,activation='relu'),\n","    layers.Dense(1,activation='sigmoid')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vZ_lDqwktmH"},"outputs":[],"source":["#compile the model\n","model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPbNVNJrlT4W","outputId":"bb06ae2b-4e33-4005-c45e-c115e427684d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","76/76 [==============================] - 1181s 16s/step - loss: 0.4617 - accuracy: 0.8011 - val_loss: 0.2678 - val_accuracy: 0.9151\n","Epoch 2/5\n","76/76 [==============================] - 293s 4s/step - loss: 0.1866 - accuracy: 0.9352 - val_loss: 0.1819 - val_accuracy: 0.9135\n","Epoch 3/5\n","76/76 [==============================] - 288s 4s/step - loss: 0.1094 - accuracy: 0.9614 - val_loss: 0.0609 - val_accuracy: 0.9784\n","Epoch 4/5\n","76/76 [==============================] - 287s 4s/step - loss: 0.0581 - accuracy: 0.9846 - val_loss: 0.0136 - val_accuracy: 0.9983\n","Epoch 5/5\n","18/76 [======>.......................] - ETA: 3:17 - loss: 0.0347 - accuracy: 0.9928"]}],"source":["model.fit(train_generator,validation_data=val_generator,epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-rdmXfWm5xR"},"outputs":[],"source":["#dont run until fit the model\n","model.save(\"Model.h5\",\"label.txt\")"]},{"cell_type":"markdown","source":["next process in Day8_Model"],"metadata":{"id":"Zv3-e78RgHuI"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np"],"metadata":{"id":"hrNVdiE7knLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load the saved filr\n","model = load_model('')"],"metadata":{"id":"PWaez55wl7YX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load and preprocess the test image\n","test_imge_path = ('')\n","img = image.load_ing(test_img_path,target_size=(224,224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array,axis=0)"],"metadata":{"id":"fEA_myBGmFzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Add batch dimension\n","img_array /= 255.   #Normalize the pixel values   -zoomin/out\n","#Make predictions\n","prediction = model.predict(img_array)\n","#print the prediction\n","print(prediction)"],"metadata":{"id":"1ctQ7VYknX6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","if prediction < 0.5:\n","  print(\"Prediction: No Tumor (Probability: )\",prediction[0][0])\n","else:\n","  print(\"Prediction: Tumor Present (Probability: )\",prediction[0][0])"],"metadata":{"id":"95UwQZHEoShI"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1VV1vfLWQ7kZFe92q9K65xCjG5YJmbr8N","authorship_tag":"ABX9TyNt25sLxPWJqk+SmnuTog8E"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}